name: Build and publish plots

on:
  schedule:
    # NBM blend cycles: 00Z, 06Z, 12Z, 18Z. Probe early (~+75m) and late (~+165m).
    - cron: "15 1 * * *"   # 00Z early
    - cron: "45 2 * * *"   # 00Z late
    - cron: "15 7 * * *"   # 06Z early
    - cron: "45 8 * * *"   # 06Z late
    - cron: "15 13 * * *"  # 12Z early
    - cron: "45 14 * * *"  # 12Z late
    - cron: "15 19 * * *"  # 18Z early
    - cron: "45 20 * * *"  # 18Z late
  workflow_dispatch:        # allow manual runs from the Actions tab

# Prevent overlapping runs
concurrency:
  group: build-plots
  cancel-in-progress: true

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install system deps for GeoPandas/Shapely/GDAL
        run: |
          sudo apt-get update
          sudo apt-get install -y gdal-bin libgdal-dev libspatialindex-dev

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt', 'WatershedForecast.py') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install Python packages
        run: |
          python -m pip install --upgrade pip
          pip install geopandas shapely xarray matplotlib pandas requests netCDF4 rtree

      # ---- Probe NOMADS for the newest NBM 1-hr blend OPeNDAP URL ----
      # If unchanged vs .github/last_forecast_url.txt, skip the build.
      - name: Probe latest forecast URL (skip if unchanged)
        id: probe
        shell: bash
        run: |
          set -euo pipefail

          python3 <<'EOF' > /tmp/probe.json
import json, os, requests
from datetime import datetime, timedelta, timezone

base = "https://nomads.ncep.noaa.gov/dods/blend"
cycles = ["18z", "12z", "06z", "00z"]  # newest first
latest = None

for day_offset in range(0, 3):
    date_str = (datetime.now(timezone.utc) - timedelta(days=day_offset)).strftime("%Y%m%d")
    for cyc in cycles:
        dds_url = f"{base}/blend{date_str}/blend_1hr_{cyc}.dds"
        try:
            r = requests.get(dds_url, timeout=6)
            if r.status_code == 200 and "Dataset" in r.text[:200]:
                latest = f"{base}/blend{date_str}/blend_1hr_{cyc}"
                break
        except requests.RequestException:
            pass
    if latest:
        break

last_file = ".github/last_forecast_url.txt"
prev = ""
if os.path.exists(last_file):
    with open(last_file, "r", encoding="utf-8") as f:
        prev = f.read().strip()

has_new = bool(latest and latest != prev)
json.dump({"latest_url": latest or "", "has_new": has_new}, open("/tmp/probe.json", "w"))
EOF

          echo "Probe ou
